{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYJI/+tFKt3OrtV49C0cvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSSamarasinghe/SE4050_Assignment/blob/IT21222740/%F0%9F%9B%925_class_Classification_Amazon_Reviews_%5BGRU_Three_Layer%5D_45_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLkA2UasUnDl",
        "outputId": "dc59645a-3f56-488b-92d6-130b8fb32909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amazon-reviews-for-sentianalysis-finegrained-csv, 654512809 bytes compressed\n",
            "[==================================================] 654512809 bytes downloaded\n",
            "Downloaded and uncompressed: amazon-reviews-for-sentianalysis-finegrained-csv\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'amazon-reviews-for-sentianalysis-finegrained-csv:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2078107%2F3499094%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240930%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240930T150806Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0384286882e57ed5979a453d3b36e2d5ac7c5683c21364a514272ce697b7a7430176301d285f6982230aa12ded3cf24f63136365e5939a1b4cf6a627f90b21b558772ac2b852ceeda8c9115147d5d45101662dbded2dc256b64c8607b23b8a2e138946585e223ab27c2e6ced66542d64b390b7a29fb5f28667574314b9b5d6a1e728981f43b957023ed099b2adfc9609101a051eb013f254b576ffd5c986f20ab81845f69f45dcde2f9c5e05f1e3fc15e3aed90b0112a274ad37e14053eb8e6d8635f649c8362c1478bc8b587d074f6474c488f679d16695f5ed6a20ddea00f6dc13ab4b1746b75013f78e36b46727d42ca74c2ba6b6d35bd214cd27c5751ebb'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and Preprocess the Data\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "oZu2yNozVqOx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('../input/amazon-reviews-for-sentianalysis-finegrained-csv/amazon_review_fine-grained_5_classes_csv/train.csv')\n",
        "data = data.sample(n=120000, random_state=42)"
      ],
      "metadata": {
        "id": "wekf-0RRVNcG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Check for Missing Values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing Values in Dataset:\\n\", missing_values)\n",
        "\n",
        "# Optionally, remove missing values if any\n",
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHOEhWeSVxuQ",
        "outputId": "f12de98c-7722-4178-8fe0-23f487be04f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values in Dataset:\n",
            " class_index     0\n",
            "review_title    8\n",
            "review_text     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Clean the Text Data\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text"
      ],
      "metadata": {
        "id": "xzRQdbzJV4CS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the clean_text function to both review_title and review_text columns\n",
        "data['review_text'] = data['review_text'].apply(clean_text)\n",
        "data['review_title'] = data['review_title'].apply(clean_text)"
      ],
      "metadata": {
        "id": "3VM255_gV7Hq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview cleaned text\n",
        "print(\"Cleaned Text Preview:\\n\", data[['review_title', 'review_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGn8qFy0V9kV",
        "outputId": "95184173-29b1-4a15-e1ce-8ed52bb7769d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text Preview:\n",
            "                                     review_title  \\\n",
            "2945667           not koontzs best but good read   \n",
            "2352586            addictiveexcept for the price   \n",
            "1531260                             same problem   \n",
            "941910   just say no to slimfast low carb shakes   \n",
            "2582125                happy thanksgiving turkey   \n",
            "\n",
            "                                               review_text  \n",
            "2945667  really i should give it three and a half stars...  \n",
            "2352586  mmmmmmm love this balm smells divine and makes...  \n",
            "1531260  pitch black plays perfectly but for some reaso...  \n",
            "941910   i am currently on a slimfast diet and found it...  \n",
            "2582125  im not much on writing reviews so i will be br...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Tokenize and Pad Sequences\n",
        "# Initialize the Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)  # Limit to top 5000 words\n",
        "tokenizer.fit_on_texts(data['review_text'])  # Fit on review text\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(data['review_text'])\n",
        "\n",
        "# Pad the sequences to ensure uniform length\n",
        "maxlen = 100  # Choose an appropriate max length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
        "\n",
        "# Convert class index to labels\n",
        "labels = data['class_index'] - 1  # Assuming class index ranges from 1 to 5\n",
        "\n",
        "# Display shape of padded sequences and labels\n",
        "print(f'Shape of Padded Sequences: {padded_sequences.shape}')\n",
        "print(f'Shape of Labels: {labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsOPGrFSWAFU",
        "outputId": "e17008a5-e109-4e53-d1c5-08f4250868f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Padded Sequences: (119992, 100)\n",
            "Shape of Labels: (119992,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Split the Data into Training and Validation Sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GNfgtSt0WIT1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Build the GRU Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
        "model.add(GRU(128, return_sequences=True))  # First GRU layer\n",
        "model.add(GRU(64, return_sequences=False))  # Second GRU layer\n",
        "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model.add(Dense(5, activation='softmax'))  # Output layer for 5 classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()  # Show the model summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "3E8dswWkWNK_",
        "outputId": "62537c67-3b5c-45cd-977b-a52dcda50d5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Train the Model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsY1ygMEWSnz",
        "outputId": "47e1a2e2-1847-45c4-9a66-f215ac967923"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m883s\u001b[0m 585ms/step - accuracy: 0.2359 - loss: 1.5797 - val_accuracy: 0.4738 - val_loss: 1.1992\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 551ms/step - accuracy: 0.4902 - loss: 1.1657 - val_accuracy: 0.4989 - val_loss: 1.1452\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 556ms/step - accuracy: 0.5276 - loss: 1.0843 - val_accuracy: 0.5049 - val_loss: 1.1279\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m865s\u001b[0m 558ms/step - accuracy: 0.5613 - loss: 1.0208 - val_accuracy: 0.5075 - val_loss: 1.1419\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m854s\u001b[0m 553ms/step - accuracy: 0.5872 - loss: 0.9598 - val_accuracy: 0.5051 - val_loss: 1.1665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Continue training the model with more epochs\n",
        "# Add more epochs to continue training\n",
        "history_more = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val), initial_epoch=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbMUsA2xdyzr",
        "outputId": "af3ffa59-cb0b-4635-bb04-1be54f911a31"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 558ms/step - accuracy: 0.6198 - loss: 0.8922 - val_accuracy: 0.5037 - val_loss: 1.1980\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m925s\u001b[0m 599ms/step - accuracy: 0.6528 - loss: 0.8303 - val_accuracy: 0.4923 - val_loss: 1.2704\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m870s\u001b[0m 565ms/step - accuracy: 0.6924 - loss: 0.7543 - val_accuracy: 0.4858 - val_loss: 1.3419\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m855s\u001b[0m 560ms/step - accuracy: 0.7330 - loss: 0.6724 - val_accuracy: 0.4781 - val_loss: 1.4624\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 561ms/step - accuracy: 0.7715 - loss: 0.5939 - val_accuracy: 0.4697 - val_loss: 1.6554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Continue training the model with more epochs\n",
        "# Add more epochs to continue training\n",
        "history_more = model.fit(X_train, y_train, epochs=13, batch_size=64, validation_data=(X_val, y_val), initial_epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0sp9mxo0JzI",
        "outputId": "b6b3c7be-3e05-444f-e20e-daf39396b1c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/13\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 462ms/step - accuracy: 0.8051 - loss: 0.5207 - val_accuracy: 0.4685 - val_loss: 1.8135\n",
            "Epoch 12/13\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 459ms/step - accuracy: 0.8383 - loss: 0.4469 - val_accuracy: 0.4609 - val_loss: 1.9282\n",
            "Epoch 13/13\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 462ms/step - accuracy: 0.8636 - loss: 0.3901 - val_accuracy: 0.4545 - val_loss: 2.0959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Continue training the model with more epochs\n",
        "# Add more epochs to continue training\n",
        "history_more = model.fit(X_train, y_train, epochs=15, batch_size=64, validation_data=(X_val, y_val), initial_epoch=13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcFE_tOVAGjc",
        "outputId": "cc9360c4-791c-4b09-ea7f-b5a8aa294afd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 461ms/step - accuracy: 0.8848 - loss: 0.3387 - val_accuracy: 0.4497 - val_loss: 2.2556\n",
            "Epoch 15/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 456ms/step - accuracy: 0.8996 - loss: 0.3007 - val_accuracy: 0.4546 - val_loss: 2.3946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Load the Test Dataset\n",
        "test = pd.read_csv('../input/amazon-reviews-for-sentianalysis-finegrained-csv/amazon_review_fine-grained_5_classes_csv/test.csv')\n",
        "\n",
        "# Step 9: Check for Missing Values in Test Dataset\n",
        "missing_values_test = test.isnull().sum()\n",
        "print(\"Missing Values in Test Dataset:\\n\", missing_values_test)\n",
        "\n",
        "# Optionally, remove missing values if any\n",
        "test.dropna(inplace=True)\n",
        "\n",
        "# Step 10: Clean the Text Data in Test Dataset\n",
        "# Apply the same clean_text function to test dataset\n",
        "test['review_text'] = test['review_text'].apply(clean_text)\n",
        "test['review_title'] = test['review_title'].apply(clean_text)\n",
        "\n",
        "# Step 11: Tokenize and Pad Sequences for Test Data\n",
        "# Convert test review text to sequences using the same tokenizer\n",
        "test_sequences = tokenizer.texts_to_sequences(test['review_text'])\n",
        "\n",
        "# Pad the test sequences to ensure uniform length (using the same maxlen)\n",
        "test_padded_sequences = pad_sequences(test_sequences, maxlen=maxlen, padding='post')\n",
        "\n",
        "# Convert class index to labels for test data\n",
        "test_labels = test['class_index'] - 1  # Assuming class index ranges from 1 to 5\n",
        "\n",
        "# Display shape of padded test sequences and test labels\n",
        "print(f'Shape of Test Padded Sequences: {test_padded_sequences.shape}')\n",
        "print(f'Shape of Test Labels: {test_labels.shape}')\n",
        "\n",
        "# Step 12: Evaluate the Model on Test Data\n",
        "test_loss, test_accuracy = model.evaluate(test_padded_sequences, test_labels)\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjwx42yzWZel",
        "outputId": "215a059c-847f-4b9b-aec5-ef71d755aec6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values in Test Dataset:\n",
            " class_index      0\n",
            "review_title    26\n",
            "review_text      0\n",
            "dtype: int64\n",
            "Shape of Test Padded Sequences: (649974, 100)\n",
            "Shape of Test Labels: (649974,)\n",
            "\u001b[1m20312/20312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1384s\u001b[0m 68ms/step - accuracy: 0.4547 - loss: 2.3944\n",
            "Test Loss: 2.3891024589538574\n",
            "Test Accuracy: 0.4544120132923126\n"
          ]
        }
      ]
    }
  ]
}